{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94gTRL_Aetds"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib numpy pandas wordcloud nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def remove_stopwords(text, custom_stopwords=None):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    if custom_stopwords:\n",
        "        stop_words.update(custom_stopwords)\n",
        "\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def generate_word_cloud(text):\n",
        "    wordcloud = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(text)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "df = pd.read_csv('all_category_1_data.csv')\n",
        "\n",
        "custom_stopwords = {'dont', 'think', 'people', 'know', 'japanese', 'thing', 'really', 'one',\n",
        "                    'went', 'well', 'said', 'time', 'thats','got','didnt','wasnt', 'things',\n",
        "                    'yeah', 'lot', 'say', 'remember', 'much', 'even', 'go', 'something',\n",
        "                    'guess', 'see', 'oh', 'u', 'kind', 'used', 'us'}\n",
        "\n",
        "cleaned_text = df['0'].apply(clean_text).apply(lambda x: remove_stopwords(x, custom_stopwords))\n",
        "\n",
        "processed_text = ' '.join(cleaned_text)\n",
        "\n",
        "generate_word_cloud(processed_text)\n"
      ],
      "metadata": {
        "id": "K2Lb4x81ewM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}