{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def ner_tags_and_entities(texts):\n",
        "    doc = nlp(texts)\n",
        "    ner_tags = [ent.label_ for ent in doc.ents]\n",
        "    entities = [ent.text for ent in doc.ents]\n",
        "    return ', '.join(ner_tags), ', '.join(entities)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "input_zip_file = 'DiscoverNikkei.zip'\n",
        "output_zip_file = 'Output_DiscoverNikkei.zip'\n",
        "temp_dir = 'temp_dir'\n",
        "os.makedirs(temp_dir)\n",
        "\n",
        "ner_tags_list = []\n",
        "entities_list = []\n",
        "\n",
        "with zipfile.ZipFile(input_zip_file, 'r') as zip_file:\n",
        "    with zipfile.ZipFile(output_zip_file, 'w') as output_zip:\n",
        "        for filename in zip_file.namelist():\n",
        "            if filename.endswith('.csv'):\n",
        "                with zip_file.open(filename) as csv_file:\n",
        "                    df = pd.read_csv(csv_file, encoding='latin1')\n",
        "                    transcripts = df['Transcript (Narrator Only)']\n",
        "\n",
        "                    file_ner_tags_list = []\n",
        "                    file_entities_list = []\n",
        "\n",
        "                    for transcript in transcripts:\n",
        "                        if pd.notna(transcript):\n",
        "                            ner_tags, entities = ner_tags_and_entities(transcript)\n",
        "                            file_ner_tags_list.append(ner_tags)\n",
        "                            file_entities_list.append(entities)\n",
        "\n",
        "                        else:\n",
        "                            file_ner_tags_list.append('')\n",
        "                            file_entities_list.append('')\n",
        "\n",
        "                    df['NER Tags'] = file_ner_tags_list\n",
        "                    df['Entities'] = file_entities_list\n",
        "\n",
        "                    output_csv_file = os.path.join(temp_dir, f'output_{filename}')\n",
        "                    df.to_csv(output_csv_file, index=False, encoding='utf-8')\n",
        "\n",
        "                    output_zip.write(output_csv_file, arcname=filename)\n"
      ],
      "metadata": {
        "id": "m8m8C4Ao1M0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For creating columns for each NER tags\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "\n",
        "def process_csv(zip_file, csv_filename):\n",
        "    with zip_file.open(csv_filename) as file:\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "    transcripts = []\n",
        "    person_entities = []\n",
        "    org_entities = []\n",
        "    event_entities = []\n",
        "    #Always in the 0th column\n",
        "    document_id = df['Document ID'][0]\n",
        "    #print(document_id)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if pd.notna(row['NER Tags']):\n",
        "            #Splitting the string into a list of tags\n",
        "            tags = row['NER Tags'].split(', ')\n",
        "\n",
        "            if any(tag in tags for tag in ['PERSON', 'ORG', 'EVENT']):\n",
        "                entities = row['Entities'].split(', ')\n",
        "\n",
        "                person_entities_row = ', '.join([entity for tag, entity in zip(tags, entities) if tag == 'PERSON'])\n",
        "                org_entities_row = ', '.join([entity for tag, entity in zip(tags, entities) if tag == 'ORG'])\n",
        "                event_entities_row = ', '.join([entity for tag, entity in zip(tags, entities) if tag == 'EVENT'])\n",
        "\n",
        "                transcripts.append(row['Transcript (Narrator Only)'])\n",
        "                person_entities.append(person_entities_row)\n",
        "                org_entities.append(org_entities_row)\n",
        "                event_entities.append(event_entities_row)\n",
        "\n",
        "    result_df = pd.DataFrame({\n",
        "        'Document ID': document_id,\n",
        "        'Transcript (Narrator)': transcripts,\n",
        "        'Person Entities': person_entities,\n",
        "        'Org Entities': org_entities,\n",
        "        'Event Entities': event_entities\n",
        "    })\n",
        "\n",
        "    return result_df\n",
        "\n",
        "input_zip_path = 'Output_DiscoverNikkei.zip'\n",
        "output_zip_path = 'DiscoverNikkei_For_EntityList.zip'\n",
        "\n",
        "with zipfile.ZipFile(input_zip_path, 'r') as input_zip:\n",
        "    with zipfile.ZipFile(output_zip_path, 'w') as output_zip:\n",
        "        for csv_filename in input_zip.namelist():\n",
        "\n",
        "            result_df = process_csv(input_zip, csv_filename)\n",
        "\n",
        "            csv_bytes = BytesIO()\n",
        "            result_df.to_csv(csv_bytes, index=False)\n",
        "            csv_bytes.seek(0)\n",
        "\n",
        "            output_zip.writestr(csv_filename, csv_bytes.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GByLuqhkT_rt",
        "outputId": "6acca1fe-f481-4698-8cc2-f92d3ab8b3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'4-33\n",
            "'4-15\n",
            "'4-41\n",
            "'4-24\n",
            "'4-23\n",
            "'4-26\n",
            "'4-16\n",
            "'4-30\n",
            "'4-10\n",
            "'4-28\n",
            "'4-14\n",
            "'4-37\n",
            "'4-34\n",
            "'4-18\n",
            "'4-22\n",
            "'4-20\n",
            "'4-1\n",
            "'4-13\n",
            "'4-35\n",
            "'4-32\n",
            "'4-38\n",
            "'4-17\n",
            "'4-12\n",
            "'4-40\n",
            "'4-11\n",
            "'4-9\n",
            "'4-5\n",
            "'4-25\n",
            "'4-6\n",
            "'4-36\n",
            "'4-7\n",
            "'4-4\n",
            "'4-29\n",
            "'4-8\n",
            "'4-39\n",
            "'4-21\n",
            "'4-31\n",
            "'4-27\n",
            "'4-3\n",
            "'4-19\n",
            "'4-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For creating lists each tags ('PERSON', 'ORG', 'EVENT')\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "input_zip_file = 'DiscoverNikkei_For_EntityList.zip'\n",
        "output_csv_file = 'DiscoverNikkei_Person_Entities_Output.csv'\n",
        "\n",
        "with zipfile.ZipFile(input_zip_file, 'r') as input_zip:\n",
        "    collected_df = pd.DataFrame()\n",
        "\n",
        "    for file_info in input_zip.infolist():\n",
        "        input_csv_path = input_zip.extract(file_info)\n",
        "\n",
        "        df = pd.read_csv(input_csv_path)\n",
        "        filtered_df = df[df['Person Entities'].notna()]\n",
        "        collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
        "\n",
        "    temp_csv_fd, temp_csv_path = tempfile.mkstemp(suffix=\".csv\")\n",
        "    os.close(temp_csv_fd)\n",
        "\n",
        "    collected_df.to_csv(temp_csv_path, index=False)\n",
        "    collected_df.to_csv(output_csv_file, index=False)\n",
        "\n",
        "    os.remove(temp_csv_path)\n",
        "\n",
        "#print(\"Processing complete. Filtered rows are saved in\", output_csv_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a5LULfgDqMH3",
        "outputId": "648e99b9-f913-478d-ee7d-07e6292da7e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n",
            "<ipython-input-113-3d5709e08b94>:26: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  collected_df = collected_df.append(filtered_df, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeEncodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-3d5709e08b94>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Save the collected DataFrame to a new CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcollected_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cp1252'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Remove the temporary CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3718\u001b[0m         )\n\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         )\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m             )\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         libwriters.write_csv_rows(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/encodings/cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\x80' in position 489: character maps to <undefined>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For merging\n",
        "import pandas as pd\n",
        "\n",
        "files = ['Densho_Event_Entities_Output.csv', 'JASC_Event_Entities_Output.csv', 'JAMSJ_Event_Entities_Output.csv', 'DiscoverNikkei_Event_Entities_Output.csv']\n",
        "\n",
        "dfs = [pd.read_csv(file, encoding='latin1') for file in files]\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "combined_df.to_csv('All_Event_Entities_Output.csv', index=False, na_rep='NaN')\n"
      ],
      "metadata": {
        "id": "W_8j1UUl0lsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydaFmoI7C9St",
        "outputId": "945ee905-ff20-45a9-9051-3a0793d9f0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tried BERT (Eventually we dodn't use this)\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"autoevaluate/entity-extraction\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"autoevaluate/entity-extraction\")\n",
        "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def ner_tags_and_entities(texts):\n",
        "    entities = ner_pipeline(texts)\n",
        "    ner_tags = [ent['entity'] for ent in entities]\n",
        "    entity_texts = [ent['word'] for ent in entities]\n",
        "    return ', '.join(ner_tags), ', '.join(entity_texts)\n",
        "\n",
        "input_zip_file = 'JASC_Transcript.zip'\n",
        "output_zip_file = 'Output_JASC.zip'\n",
        "temp_dir = 'temp_dir'\n",
        "os.makedirs(temp_dir)\n",
        "\n",
        "ner_tags_list = []\n",
        "entities_list = []\n",
        "\n",
        "with zipfile.ZipFile(input_zip_file, 'r') as zip_file:\n",
        "    with zipfile.ZipFile(output_zip_file, 'w') as output_zip:\n",
        "        for filename in zip_file.namelist():\n",
        "            if filename.endswith('.csv'):\n",
        "                with zip_file.open(filename) as csv_file:\n",
        "                    df = pd.read_csv(csv_file, encoding='latin1')\n",
        "                    transcripts = df['Transcript (Narrator)']\n",
        "\n",
        "                    file_ner_tags_list = []\n",
        "                    file_entities_list = []\n",
        "\n",
        "                    for transcript in transcripts:\n",
        "                        if pd.notna(transcript):\n",
        "                            ner_tags, entities = ner_tags_and_entities(transcript)\n",
        "                            file_ner_tags_list.append(ner_tags)\n",
        "                            file_entities_list.append(entities)\n",
        "                        else:\n",
        "                            file_ner_tags_list.append('')\n",
        "                            file_entities_list.append('')\n",
        "\n",
        "                    df['NER Tags'] = file_ner_tags_list\n",
        "                    df['Entities'] = file_entities_list\n",
        "\n",
        "                    output_csv_file = os.path.join(temp_dir, f'output_{filename}')\n",
        "                    df.to_csv(output_csv_file, index=False, encoding='utf-8')\n",
        "\n",
        "                    output_zip.write(output_csv_file, arcname=filename)\n"
      ],
      "metadata": {
        "id": "AbCJaPhBBcxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
